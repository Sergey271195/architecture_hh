# architecture_hh

1. Представим, что у нас есть данные, которые мы очень часто читаем по сравнению с другими(например словарь стран). 
Как можно это оптимизировать?

Использовать кэширование данных. В зависмости от ситуации можно кэшировать данные на уровне базы,
на уровне приложения,  кэшировать на сервере, в браузере у клиента.
Возможно использование Memcached, Redis. В hibernate также есть два уровня кэширования.

2. Что можно сделать, если таблица вакансий стала слишком большой? Какие есть решения на уровне текущей базы данных? 
Можно ли ее чем то заменить?

Если проблема возникла с хранением базы, то возможно применение шардирования таблицы и хранения различных частей
этой таблицы на различных серверах.
Если проблема возникает с увеличением времени поиска данных в таблице, возможно:
а) Применение партицирования таблицы (например по городу). Так мы будем в зависимости от города хранить данные в отдельных таблицах
и при запросе соответственно обращаться к меньшему числу записей.
б) Настрока индексов в таблцие (Индексация по наиболее часто используемым для поиска ключам таблицы)
в) Использование нескольких read-only реплик базы
г) Увеличение пула соеднинений с базой
Если искать решение не на уровне базы, то можно использовать поисковую систему (Lucene, Elastitcsearch)

3. Какие вы видите узкие места, возможно неправильно выбранные технологии в текущей схеме
(можно рассмотреть как “нашу” схему, так и схему настоящего hh.ru)

а) Несмотря на то, что бизнес логика разнесена по разым микросервисам, все запросы проходят через logic и jlogic.
В этом случае при появлении нового микросервиса приходится вносить изменения в достаточно монолитные logic, jlogic.
Нужна отдельная команда для осуществления интеграции новых микросервисов с logic, jlogic.

б) Из-за большого количества микросервисов возникают сложности с реализацией взаимодесйтвия между ними. 
Возможно возникновение циклических запросов. В случае возникновения ошибки сложно определить ее источник.
Так как все сервисы взаимодейстуют друг с другом, сложно отслеживать связи между микросервисами, сложно это взаимодействие
тестировать (огромное количество эндпоинтов, для тестирования одного микросервиса необходимо поднимать
все микросервисы, с которыми он взаимодействует)
Обмен данными между сервисами за счет сетевого оверхеда и обработки данных выходит дороже, чем в монолитном приложении. 

в) Возможность применения различных языков может быть как преимуществом, так и недостатком. Поскольку чем больше
языков/технологий используется, тем больше нужно специалистов разных профилей. 

г) Если разные микросервисы используют разные бд, сложно поддерживать консистентность данных.

д) Чем больше система разрастается, тем сложнее ее поддерживать и контролировать, необходимо использование инструментов оркестровки.

Выбор технологий, на мой взгляд, определяется в первую очередь решаемой бизнес задачей. Поэтому сложно делать выводы
о применяемых инструментах. Поскольку работать приходится с уже сложившейся системой, необходимо во многом идти на компромисы.
Возможность применения новых языков/технологий, реструктуризация системы, рефакторинг кода должны быть обоснованы. 
(Мне бы хотелось поработать с GraphQL вместо REST, но насколько это оправдано для сложившейся системы?)
Было бы удобно построить красивую архитектуру с нуля, но это будут значительные и неоправданные издержки, к тому же в дальнейшем система
может измениться, что вновь приведет к нарушению стройной структуры
